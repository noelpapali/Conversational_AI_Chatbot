name: Daily Scraper Execution

on:
  schedule:
    - cron: '0 14 * * *'  # 2PM UTC daily
  workflow_dispatch:       # Manual trigger option

permissions:
  contents: write  # Required for committing scraped data back to repo

jobs:
  execute-scrapers:
    runs-on: ubuntu-latest
    timeout-minutes: 45    # Increased timeout for long-running scrapers

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          path: 'chatbot'  # Explicit checkout path
          fetch-depth: 0   # Required for git operations

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r chatbot/requirements.txt
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver

      - name: Set up environment
        run: |
          echo "GITHUB_ACTIONS=true" >> $GITHUB_ENV
          echo "CHROME_PATH=$(which chromium-browser)" >> $GITHUB_ENV
          mkdir -p chatbot/scraper_logs
          mkdir -p chatbot/scraped_data_git
          mkdir -p chatbot/tables

      - name: Install logging config module
        run: |
          cp chatbot/logging_config.py chatbot/scraper/

      - name: Execute main scraper controller
        working-directory: ./chatbot
        run: |
          python run_scrapers.py 2>&1 | tee scraper_logs/run_$(date +'%Y%m%d_%H%M%S').log

      - name: Verify scraped files
        working-directory: ./chatbot
        run: |
          echo "=== SCRAPED DATA VERIFICATION ==="
          echo "Directory structure:"
          ls -l scraped_data_git/
          echo -e "\nFile contents:"
          find scraped_data_git/ -type f -print -exec cat {} \;

      - name: Commit scraped data
        if: success()
        working-directory: ./chatbot
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add scraped_data_git/
          if ! git diff-index --quiet HEAD; then
            git commit -m "Auto-update scraped data [skip ci]"
            git push
            echo "Changes committed successfully"
          else
            echo "No changes to commit"
          fi

      - name: Upload execution logs
        uses: actions/upload-artifact@v4
        with:
          name: scraper-execution-logs
          path: chatbot/scraper_logs/*.log
          retention-days: 7

      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data
          path: |
            chatbot/scraped_data_git/*
            chatbot/tables/*
          retention-days: 7

      - name: Final status notification
        if: always()
        run: |
          echo "::notice::Scraper execution completed with status: ${{ job.status }}"
          echo "View detailed logs: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "Failed scrapers (if any): program_links_utd_s.py, utd_programs_data_s.py, tuition_rates_content.py, scholarship_data_s.py"